{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "from itertools import chain\n",
    "import urllib.request as request\n",
    "import pickle \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import scipy.signal as signal\n",
    "import scipy.special as special\n",
    "import scipy.optimize as optimize\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import skimage.io\n",
    "import skimage.transform\n",
    "from skimage.restoration import estimate_sigma\n",
    "\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "\n",
    "from libsvm import svmutil\n",
    "\n",
    "import torch  \n",
    "import torch.nn.functional as F\n",
    "from PIL import Image, ImageStat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load(img_path):\n",
    "    if isinstance(img_path, str):\n",
    "        if os.path.exists(img_path):\n",
    "            image = cv2.imread(img_path)\n",
    "            grimage = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "        else:\n",
    "            raise FileNotFoundError('Image is not found on your system')\n",
    "    else:\n",
    "        raise ValueError('Only image can be passed to the constructor')\n",
    "    return image, grimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_noise(img):\n",
    "    H, W = img.shape\n",
    "    M = [[1, -2, 1],\n",
    "       [-2, 4, -2],\n",
    "       [1, -2, 1]]\n",
    "\n",
    "    sigma = np.sum(np.sum(np.absolute(signal.convolve2d(img, M))))\n",
    "    sigma = sigma * math.sqrt(0.5 * math.pi) / (6 * (W-2) * (H-2))\n",
    "    return sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contrast(img):\n",
    "    contrast = img.std()\n",
    "    return contrast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brightness(img):\n",
    "    im = Image.open(img)\n",
    "    stat = ImageStat.Stat(im)\n",
    "\n",
    "    band = stat.mean\n",
    "    r = band[0]\n",
    "    g = band[1]\n",
    "    b = band[2]\n",
    "    return math.sqrt(0.241*(r**2) + 0.691*(g**2) + 0.068*(b**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = None\n",
    "Im = None\n",
    "edgex, edgey = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dom(Im):\n",
    "    median_shift_up = np.pad(Im, ((0,2), (0,0)), 'constant')[2:,:]\n",
    "    median_shift_down = np.pad(Im, ((2,0), (0,0)), 'constant')[:-2,:]\n",
    "    domx = np.abs(median_shift_up - 2*Im + median_shift_down)\n",
    "\n",
    "    median_shift_left = np.pad(Im, ((0,0), (0,2)), 'constant')[:,2:]\n",
    "    median_shift_right = np.pad(Im, ((0,0), (2,0)), 'constant')[:,:-2]\n",
    "    domy = np.abs(median_shift_left - 2*Im + median_shift_right)\n",
    "    return domx, domy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrast(Im):\n",
    "        Cx = np.abs(Im - np.pad(Im, ((1,0), (0,0)), 'constant')[:-1, :])\n",
    "        Cy = np.abs(Im - np.pad(Im, ((0,0), (1,0)), 'constant')[:, :-1])\n",
    "        return Cx, Cy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smoothenImage(image):\n",
    "    fil = np.array([0.5, 0, -0.5])\n",
    "    image_smoothed = np.array([np.convolve(image[i], fil, mode=\"same\") for i in range(image.shape[0])])\n",
    "\n",
    "    image_smoothed = np.abs(image_smoothed)/(np.max(image_smoothed) + 1e-8)\n",
    "    return image_smoothed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edges(image, edge_threshold=0.0001):\n",
    "    smoothx = smoothenImage(image, transpose=True)\n",
    "    smoothy = smoothenImage(image)\n",
    "    global edgex\n",
    "    edgex = smoothx > edge_threshold\n",
    "    global edgey\n",
    "    edgey = smoothy > edge_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpness_matrix(Im, width=2):\n",
    "    domx, domy = dom(Im)\n",
    "\n",
    "    Cx, Cy = contrast(Im)\n",
    "\n",
    "    Cx = np.multiply(Cx, edgex)\n",
    "    Cy = np.multiply(Cy, edgey)\n",
    "\n",
    "    Sx = np.zeros(domx.shape)\n",
    "    Sy = np.zeros(domy.shape)\n",
    "\n",
    "    for i in range(width, domx.shape[0]-width):\n",
    "        num = np.abs(domx[i-width:i+width, :]).sum(axis=0)\n",
    "        dn = Cx[i-width:i+width, :].sum(axis=0)\n",
    "        Sx[i] = [(num[k]/dn[k] if dn[k] > 1e-3 else 0) for k in range(Sx.shape[1])]\n",
    "    for j in range(width, domy.shape[1]-width):\n",
    "        num = np.abs(domy[:, j-width: j+width]).sum(axis=1)\n",
    "        dn = Cy[:, j-width:j+width].sum(axis=1)\n",
    "        Sy[:, j] = [(num[k]/dn[k] if dn[k] > 1e-3 else 0) for k in range(Sy.shape[0])]\n",
    "    return Sx, Sy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharpness_measure(Im, width, sharpness_threshold, epsilon = 1e-8):\n",
    "    Sx, Sy = sharpness_matrix(Im, width=width)\n",
    "    Sx = np.multiply(Sx, edgex)\n",
    "    Sy = np.multiply(Sy, edgey)\n",
    "\n",
    "    n_sharpx = np.sum(Sx >= sharpness_threshold)\n",
    "    n_sharpy = np.sum(Sy >= sharpness_threshold)\n",
    "\n",
    "    n_edgex = np.sum(edgex)\n",
    "    n_edgey = np.sum(edgey)\n",
    "\n",
    "    Rx = n_sharpx/(n_edgex + 1e-8)\n",
    "    Ry = n_sharpy/(n_edgey + 1e-8)\n",
    "\n",
    "    S = np.sqrt(Rx**2 + Ry**2)\n",
    "    return S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sharpness(img, width=2, sharpness_threshold=2, edge_threshold=0.0001, debug=False):\n",
    "    Im = cv2.medianBlur(img, 3, cv2.CV_64F).astype(\"double\")/255.0\n",
    "    edges(img, edge_threshold=edge_threshold)\n",
    "    score = sharpness_measure(Im, width=width, sharpness_threshold=sharpness_threshold)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_kernel(kernel):\n",
    "    return kernel / np.sum(kernel)\n",
    "\n",
    "def gaussian_kernel2d(n, sigma):\n",
    "    Y, X = np.indices((n, n)) - int(n/2)\n",
    "    gaussian_kernel = 1 / (2 * np.pi * sigma ** 2) * np.exp(-(X ** 2 + Y ** 2) / (2 * sigma ** 2)) \n",
    "    return normalize_kernel(gaussian_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def local_deviation(image, local_mean, kernel):\n",
    "    sigma = image ** 2\n",
    "    sigma = signal.convolve2d(sigma, kernel, 'same')\n",
    "    return np.sqrt(np.abs(local_mean ** 2 - sigma))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_mscn_coefficients(image, kernel_size=6, sigma=7/6):\n",
    "    C = 1/255\n",
    "    kernel = gaussian_kernel2d(kernel_size, sigma=sigma)\n",
    "    local_mean = signal.convolve2d(image, kernel, 'same')\n",
    "    local_var = local_deviation(image, local_mean, kernel)\n",
    "    return (image - local_mean) / (local_var + C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generalized_gaussian_dist(x, alpha, sigma):\n",
    "    beta = sigma * np.sqrt(special.gamma(1 / alpha) / special.gamma(3 / alpha))\n",
    "    coefficient = alpha / (2 * beta() * special.gamma(1 / alpha))\n",
    "    return coefficient * np.exp(-(np.abs(x) / beta) ** alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pair_product_coefficients(mscn_coefficients):\n",
    "    return collections.OrderedDict({\n",
    "        'mscn': mscn_coefficients,\n",
    "        'horizontal': mscn_coefficients[:, :-1] * mscn_coefficients[:, 1:],\n",
    "        'vertical': mscn_coefficients[:-1, :] * mscn_coefficients[1:, :],\n",
    "        'main_diagonal': mscn_coefficients[:-1, :-1] * mscn_coefficients[1:, 1:],\n",
    "        'secondary_diagonal': mscn_coefficients[1:, :-1] * mscn_coefficients[:-1, 1:]\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asymmetric_generalized_gaussian(x, nu, sigma_l, sigma_r):\n",
    "    def beta(sigma):\n",
    "        return sigma * np.sqrt(special.gamma(1 / nu) / special.gamma(3 / nu))\n",
    "    \n",
    "    coefficient = nu / ((beta(sigma_l) + beta(sigma_r)) * special.gamma(1 / nu))\n",
    "    f = lambda x, sigma: coefficient * np.exp(-(x / beta(sigma)) ** nu)\n",
    "        \n",
    "    return np.where(x < 0, f(-x, sigma_l), f(x, sigma_r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def asymmetric_generalized_gaussian_fit(x):\n",
    "    def estimate_phi(alpha):\n",
    "        numerator = special.gamma(2 / alpha) ** 2\n",
    "        denominator = special.gamma(1 / alpha) * special.gamma(3 / alpha)\n",
    "        return numerator / denominator\n",
    "\n",
    "    def estimate_r_hat(x):\n",
    "        size = np.prod(x.shape)\n",
    "        return (np.sum(np.abs(x)) / size) ** 2 / (np.sum(x ** 2) / size)\n",
    "\n",
    "    def estimate_R_hat(r_hat, gamma):\n",
    "        numerator = (gamma ** 3 + 1) * (gamma + 1)\n",
    "        denominator = (gamma ** 2 + 1) ** 2\n",
    "        return r_hat * numerator / denominator\n",
    "\n",
    "    def mean_squares_sum(x, filter = lambda z: z == z):\n",
    "        filtered_values = x[filter(x)]\n",
    "        squares_sum = np.sum(filtered_values ** 2)\n",
    "        return squares_sum / ((filtered_values.shape))\n",
    "\n",
    "    def estimate_gamma(x):\n",
    "        left_squares = mean_squares_sum(x, lambda z: z < 0)\n",
    "        right_squares = mean_squares_sum(x, lambda z: z >= 0)\n",
    "\n",
    "        return np.sqrt(left_squares) / np.sqrt(right_squares)\n",
    "\n",
    "    def estimate_alpha(x):\n",
    "        r_hat = estimate_r_hat(x)\n",
    "        gamma = estimate_gamma(x)\n",
    "        R_hat = estimate_R_hat(r_hat, gamma)\n",
    "\n",
    "        solution = optimize.root(lambda z: estimate_phi(z) - R_hat, [0.2]).x\n",
    "\n",
    "        return solution[0]\n",
    "\n",
    "    def estimate_sigma(x, alpha, filter = lambda z: z < 0):\n",
    "        return np.sqrt(mean_squares_sum(x, filter))\n",
    "    \n",
    "    def estimate_mean(alpha, sigma_l, sigma_r):\n",
    "        return (sigma_r - sigma_l) * constant * (special.gamma(2 / alpha) / special.gamma(1 / alpha))\n",
    "    \n",
    "    alpha = estimate_alpha(x)\n",
    "    sigma_l = estimate_sigma(x, alpha, lambda z: z < 0)\n",
    "    sigma_r = estimate_sigma(x, alpha, lambda z: z >= 0)\n",
    "    \n",
    "    constant = np.sqrt(special.gamma(1 / alpha) / special.gamma(3 / alpha))\n",
    "    mean = estimate_mean(alpha, sigma_l, sigma_r)\n",
    "    \n",
    "    return alpha, mean, sigma_l, sigma_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_brisque_features(image, kernel_size=7, sigma=7/6):\n",
    "    def calculate_features(coefficients_name, coefficients, accum=np.array([])):\n",
    "        alpha, mean, sigma_l, sigma_r = asymmetric_generalized_gaussian_fit(coefficients)\n",
    "\n",
    "        if coefficients_name == 'mscn':\n",
    "            var = (sigma_l ** 2 + sigma_r ** 2) / 2\n",
    "            return [alpha, var]\n",
    "        \n",
    "        return [alpha, mean, sigma_l ** 2, sigma_r ** 2]\n",
    "    \n",
    "    mscn_coefficients = calculate_mscn_coefficients(image, kernel_size, sigma)\n",
    "    coefficients = calculate_pair_product_coefficients(mscn_coefficients)\n",
    "    \n",
    "    features = [calculate_features(name, coeff) for name, coeff in coefficients.items()]\n",
    "    flatten_features = list(chain.from_iterable(features))\n",
    "    return np.array(flatten_features, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_features(features):\n",
    "    with open('normalize.pickle', 'rb') as handle:\n",
    "        scale_params = pickle.load(handle)\n",
    "    \n",
    "    min_ = np.array(scale_params['min_'])\n",
    "    max_ = np.array(scale_params['max_'])\n",
    "    \n",
    "    return -1 + (2.0 / (max_ - min_) * (features - min_))\n",
    "\n",
    "def calculate_image_quality_score(brisque_features):\n",
    "    model = svmutil.svm_load_model('brisque_svm.txt')\n",
    "    scaled_brisque_features = scale_features(brisque_features)\n",
    "    \n",
    "    x, idx = svmutil.gen_svm_nodearray(\n",
    "        scaled_brisque_features,\n",
    "        isKernel=(model.param.kernel_type == svmutil.PRECOMPUTED))\n",
    "    \n",
    "    nr_classifier = 1\n",
    "    prob_estimates = (svmutil.c_double * nr_classifier)()\n",
    "    \n",
    "    return svmutil.libsvm.svm_predict_probability(model, x, prob_estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_brisque(img):\n",
    "    image = skimage.io.imread(img)\n",
    "    gray_image = skimage.color.rgb2gray(image)\n",
    "    mscn_coefficients = calculate_mscn_coefficients(gray_image, 7, 7/6)\n",
    "    coefficients = calculate_pair_product_coefficients(mscn_coefficients)\n",
    "    brisque_features = calculate_brisque_features(gray_image, kernel_size=7, sigma=7/6)\n",
    "    downscaled_image = cv2.resize(gray_image, None, fx=1/2, fy=1/2, interpolation = cv2.INTER_CUBIC)\n",
    "    downscale_brisque_features = calculate_brisque_features(downscaled_image, kernel_size=7, sigma=7/6)\n",
    "    brisque_features = np.concatenate((brisque_features, downscale_brisque_features))\n",
    "    return calculate_image_quality_score(brisque_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(window_size, sigma):\n",
    "    gauss =  torch.Tensor([math.exp(-(x - window_size//2)**2/float(2*sigma**2)) for x in range(window_size)])\n",
    "    return gauss/gauss.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_window(window_size, channel=1):\n",
    "    _1d_window = gaussian(window_size=window_size, sigma=1.5).unsqueeze(1)\n",
    "    _2d_window = _1d_window.mm(_1d_window.t()).float().unsqueeze(0).unsqueeze(0)\n",
    "    window = torch.Tensor(_2d_window.expand(channel, 1, window_size, window_size).contiguous())\n",
    "    return window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssim(img1, img2, val_range, window_size=11, window=None):\n",
    "    L = val_range\n",
    "    pad = window_size // 2\n",
    "    \n",
    "    try:\n",
    "        _, channels, height, width = img1.size()\n",
    "    except:\n",
    "        channels, height, width = img1.size()\n",
    "\n",
    "    if window is None: \n",
    "        real_size = min(window_size, height, width)\n",
    "        window = create_window(real_size, channel=channels).to(img1.device)\n",
    "\n",
    "    mu1 = F.conv2d(img1, window, padding=pad, groups=channels)\n",
    "    mu2 = F.conv2d(img2, window, padding=pad, groups=channels)\n",
    "    mu1_sq = mu1 ** 2\n",
    "    mu2_sq = mu2 ** 2 \n",
    "    mu12 = mu1 * mu2\n",
    "    sigma1_sq = F.conv2d(img1 * img1, window, padding=pad, groups=channels) - mu1_sq\n",
    "    sigma2_sq = F.conv2d(img2 * img2, window, padding=pad, groups=channels) - mu2_sq\n",
    "    sigma12 =  F.conv2d(img1 * img2, window, padding=pad, groups=channels) - mu12\n",
    "    C1 = (0.01 ) ** 2\n",
    "    C2 = (0.03 ) ** 2 \n",
    "\n",
    "    contrast_metric = (2.0 * sigma12 + C2) / (sigma1_sq + sigma2_sq + C2)\n",
    "    contrast_metric = torch.mean(contrast_metric)\n",
    "    numerator1 = 2 * mu12 + C1  \n",
    "    numerator2 = 2 * sigma12 + C2\n",
    "    denominator1 = mu1_sq + mu2_sq + C1 \n",
    "    denominator2 = sigma1_sq + sigma2_sq + C2\n",
    "\n",
    "    ssim_score = (numerator1 * numerator2) / (denominator1 * denominator2)\n",
    "    return ssim_score.mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_SSIM(img1, img2):\n",
    "    load_images = lambda x: np.asarray(Image.open(x).resize((480, 640)))\n",
    "    tensorify = lambda x: torch.Tensor(x.transpose((2, 0, 1))).unsqueeze(0).float().div(255.0)\n",
    "    img1 = load_images(img1)\n",
    "    img2 = load_images(img2)\n",
    "    gauss_dis = gaussian(11, 1.5)\n",
    "    window = create_window(11, 3)\n",
    "    timg1 = tensorify(img1)\n",
    "    timg2 = tensorify(img2)\n",
    "    score = ssim(_img1, _img2, val_range=255)\n",
    "    point = float(str(gg)[7:-1])\n",
    "    return point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dynamic_range(img):\n",
    "    dynamic_range = []\n",
    "    image = cv2.imread(img, cv2.IMREAD_COLOR)\n",
    "    pixel_brightness = []\n",
    "    for x in range (1,480):\n",
    "        for y in range (1,640):\n",
    "            try:\n",
    "                pixel = image[x,y]\n",
    "                R, G, B = pixel\n",
    "                brightness = sum([R,G,B])/3\n",
    "                pixel_brightness.append(brightness)\n",
    "            except IndexError:\n",
    "                pass\n",
    "    dyn_range = round(np.log2(max(pixel_brightness))-np.log2(min((pixel_brightness))), 2)\n",
    "    dynamic_range.append(dyn_range)\n",
    "    return dynamic_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IQA(img_path, img2_path=False):\n",
    "    if img2_path:\n",
    "        colomns = ['SSIM']\n",
    "        df_scale = pd.DataFrame(index=range(1), columns=colomns)\n",
    "        df_interp = pd.DataFrame(index=range(1), columns=colomns)\n",
    "        im1 = load(img_path)\n",
    "        im2 = load(img2_path)\n",
    "        df_scale['SSIM'][0] = get_SSIM(img_path, img2_path)\n",
    "        if df_scale['SSIM'][0] == 1:\n",
    "            df_interp['SSIM'][0] = 'Exact same'\n",
    "        elif df_scale['SSIM'][0] > 0.8:\n",
    "            df_interp['SSIM'][0] = 'Very similar'\n",
    "        elif df_scale['SSIM'][0] > 0.5:\n",
    "            df_interp['SSIM'][0] = 'Similar'\n",
    "        else:\n",
    "            df_interp['SSIM'][0] = 'Not similar'\n",
    "        \n",
    "        return df_scale, df_interp\n",
    "    \n",
    "    else:\n",
    "        colomns = ['Noise', 'Brightness', 'Contrast', 'Sharpness', 'BRISQUE', 'Dynamic Range']\n",
    "        df_scale = pd.DataFrame(index=range(1), columns=colomns)\n",
    "        df_interp = pd.DataFrame(index=range(1), columns=colomns)\n",
    "\n",
    "        origimg, greyimg = load(img_path)\n",
    "\n",
    "        df_scale['Noise'][0] = get_noise(grimg)\n",
    "        if df_scale['Noise'][0] > 10:\n",
    "            df_interp['Noise'][0] = 'Very noisy'\n",
    "        elif df_scale['Noise'][0] > 5:\n",
    "            df_interp['Noise'][0] = 'Noisy'\n",
    "        else:\n",
    "            df_interp['Noise'][0] = 'Non-noisy'\n",
    "\n",
    "        df_scale['Contrast'][0] = get_contrast(grimg)\n",
    "        if df_scale['Contrast'][0] > 40:\n",
    "            df_interp['Contrast'][0] = 'High contrast'\n",
    "        else:\n",
    "            df_interp['Contrast'][0] = 'Low contrast'\n",
    "\n",
    "        df_scale['Brightness'][0] = get_brightness(img_path)\n",
    "        if df_scale['Brightness'][0] > 200:\n",
    "            df_interp['Brightness'][0] = 'Very high brightness'\n",
    "        elif df_scale['Brightness'][0] > 120:\n",
    "            df_interp['Brightness'][0] = 'High brightness'\n",
    "        elif df_scale['Brightness'][0] > 20:\n",
    "            df_interp['Brightness'][0] = 'Low brightness'\n",
    "        else:\n",
    "            df_interp['Brightness'][0] = 'Very low brightness'\n",
    "\n",
    "        df_scale['Sharpness'][0] = get_sharpness(grimg)\n",
    "        if df_scale['Sharpness'][0] > 1:\n",
    "            df_interp['Sharpness'][0] = 'Very sharp'\n",
    "        elif df_scale['Sharpness'][0] > math.sqrt(2)/2:\n",
    "            df_interp['Sharpness'][0] = 'Sharp'\n",
    "        elif df_scale['Sharpness'][0] > 0.3:\n",
    "            df_interp['Sharpness'][0] = 'Unsharp'\n",
    "        else:\n",
    "            df_interp['Sharpness'][0] = 'Very unsharp'\n",
    "\n",
    "        df_scale['BRISQUE'][0] = get_brisque(img_path)\n",
    "        if df_scale['BRISQUE'][0] > 80:\n",
    "            df_interp['BRISQUE'][0] = 'Very good'\n",
    "        elif df_scale['BRISQUE'][0] > 50:\n",
    "            df_interp['BRISQUE'][0] = 'Good'\n",
    "        elif df_scale['BRISQUE'][0] > 20:\n",
    "            df_interp['BRISQUE'][0] = 'Bad'\n",
    "        else:\n",
    "            df_interp['BRISQUE'][0] = 'Very bad'\n",
    "            \n",
    "        df_scale['Dynamic Range'][0] = get_dynamic_range(img_path)\n",
    "        if df_scale['Dynamic Range'][0] > 14:\n",
    "            df_interp['Dynamic Range'][0] = 'Full sunlight'\n",
    "        elif df_scale['Dynamic Range'][0] > 12:\n",
    "            df_interp['Dynamic Range'][0] = 'Cloudy'\n",
    "        else:\n",
    "            df_interp['Dynamic Range'][0] = 'Deep shade'\n",
    "\n",
    "        return df_scale, df_interp"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
